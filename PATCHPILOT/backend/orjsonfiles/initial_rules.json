"After analyzing the input rules, I have detected semantic overlap or duplication. Here's the output:\n\n```\n{\n  \"final_rules\": [\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings if not detected automatically.\",\n      \"priority\": \"CRITICAL\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker.\",\n      \"priority\": \"CRITICAL\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama.\",\n      \"priority\": \"CRITICAL\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Verify that Ollama server is running before attempting any fixes or URL changes.\",\n      \"priority\": \"CRITICAL\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA AND OLLAMA_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama and verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama) AND General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL FOR_DOCKER\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker.\",\n      \"priority\": \"CRITICAL | HIGH\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA AND OLLAMA_SERVER_MUST_BE_RUNNING FOR_DOCKER\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama and verify that Ollama server is running when running AnythingLLM via Docker.\",\n      \"priority\": \"CRITICAL | HIGH\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama) AND General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA OR OLLAMA_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama or verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama) OR General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL OR OLLAMA_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker or verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Docker) OR General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings if not detected automatically.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Verify that Ollama server is running before attempting any fixes or URL changes.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA AND OLLAMA_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama and verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama) AND General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL FOR_DOCKER AND OLLAMA_SERVER_MUST_BE_RUNNING\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker and verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Docker) AND General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_SET_FOR_REMOTE_OLLAMA OR OLLAMA_SERVER_MUST_BE_RUNNING FOR_DOCKER\",\n      \"rule_text\": \"Set Ollama URL in AnythingLLM settings for remote Ollama or verify that Ollama server is running when running AnythingLLM via Docker.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\",\n      \"sources\": [\n        {\n          \"url\": \"https://docs.useanything.com/ollama-connection-troubleshooting\",\n          \"evidence_snippet\": \"Troubleshooting (Remote Ollama) OR General Troubleshooting (Desktop & Docker)\"\n        }\n      ]\n    },\n    {\n      \"rule_id\": \"Ollama_URL_MUST_BE_LOCALHOST_OR_HOSTDOCKER_INTERNAL OR OLLAMA_SERVER_MUST_BE_RUNNING FOR_DOCKER\",\n      \"rule_text\": \"Use localhost or host.docker.internal instead of 127.0.0.1 when running AnythingLLM via Docker or verify that Ollama server is running.\",\n      \"priority\": \"CRITICAL | HIGH | MEDIUM | LOW\","